{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa888588-d0a0-497f-9b82-244a75381507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 notification messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gautham Rajesh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved notification index.\n",
      "\n",
      " Suggested Between-Session Message:\n",
      "\n",
      "**Message:**\n",
      "\n",
      "\"Remember, it's okay to feel resistant. Instead of avoiding those feelings, try to make space for them. When you notice discomfort, take a moment to observe it without judgment. Ask yourself: what values are guiding you in this moment? This can help you choose how to respond rather than react. You have the strength to explore these feelings at your own pace.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "\n",
    "# Setting up my OpenAI client\n",
    "OPENAI_API_KEY = \"Your API Key\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Loading the notification messages from file\n",
    "def load_notifications(filepath=\"notifications.txt\"):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return [chunk.strip() for chunk in text.strip().split(\"\\n\\n\") if chunk.strip()]\n",
    "\n",
    "notification_chunks = load_notifications(\"notifications.txt\")\n",
    "print(f\"Loaded {len(notification_chunks)} notification messages.\")\n",
    "\n",
    "# Creating embeddings and building a FAISS index for notifications\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "notification_embeddings = embedding_model.encode(notification_chunks, convert_to_numpy=True)\n",
    "\n",
    "dimension = notification_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(notification_embeddings.astype(\"float32\"))\n",
    "\n",
    "with open(\"notification_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(notification_chunks, f, indent=2)\n",
    "faiss.write_index(index, \"notification_index.faiss\")\n",
    "\n",
    "print(\"Saved notification index.\")\n",
    "\n",
    "# Reading the session summary and partial transcript\n",
    "with open(\"Chat Gpt S3 Bottom Up Summary.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_summary = f.read().strip()\n",
    "\n",
    "with open(\"Session Three.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_transcript = f.read().strip()\n",
    "\n",
    "# Limiting the transcript to 700 words for processing\n",
    "session_transcript = ' '.join(session_transcript.split()[:700])\n",
    "\n",
    "# Retrieving top-k relevant candidate messages based on session summary\n",
    "query_embedding = embedding_model.encode([session_summary], convert_to_numpy=True)\n",
    "D, I = index.search(np.array(query_embedding).astype(\"float32\"), k=3)\n",
    "top_messages = [notification_chunks[i] for i in I[0]]\n",
    "\n",
    "# Building system and user prompts for message selection\n",
    "system_prompt = \"You are a psychologist selecting a helpful message to send to a client between sessions. Use ACT (Acceptance and Commitment Therapy) principles.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Session Summary:\n",
    "---\n",
    "{session_summary}\n",
    "\n",
    "Transcript (partial):\n",
    "---\n",
    "{session_transcript}\n",
    "\n",
    "Candidate Messages:\n",
    "---\n",
    "{chr(10).join(top_messages)}\n",
    "\n",
    "Task:\n",
    "Choose the best message for this client or rewrite a better one.\n",
    "It should be:\n",
    "- Short and supportive\n",
    "- Actionable (something the client can reflect on or practice)\n",
    "- Grounded in ACT processes (defusion, acceptance, values, committed action)\n",
    "\"\"\"\n",
    "\n",
    "# Asking the model for the best between-session message\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "# Printing the suggested message\n",
    "suggested_message = response.choices[0].message.content.strip()\n",
    "print(\"\\nSuggested Between-Session Message:\\n\")\n",
    "print(suggested_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1452bff9-4c35-4618-ba05-b0021f894a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 notification messages.\n",
      "Saved notification index.\n",
      "\n",
      " Suggested Between-Session Message:\n",
      "\n",
      "<think>\n",
      "Alright, let's tackle this. The user wants a helpful ACT-based message for a client who's showing resistance to homework and avoidance patterns. \n",
      "\n",
      "Looking at the session summary, the client's core struggle is clear: they're avoiding emotional discomfort by dismissing the homework as irrelevant, inconvenient, or untrustworthy. Their resistance manifests as intellectualization (bringing journal articles), distrust of quantification (\"I don't like numbers\"), and frustration with revisiting difficult experiences (\"why dredge it up?\"). \n",
      "\n",
      "The therapist skillfully framed this as experiential avoidance and cognitive fusion - classic ACT targets. The client's momentary acknowledgment (\"I don't know why I'm so resistant\") suggests a sliver of willingness we can leverage. \n",
      "\n",
      "Key ACT principles to emphasize:\n",
      "- Workability over rationality (what works vs what \"makes sense\")\n",
      "- Willingness to experience discomfort in service of values\n",
      "- Defusion from \"I can't trust this\" thoughts\n",
      "- Small committed actions amid resistance\n",
      "\n",
      "The candidate messages each have merits but miss the mark slightly:\n",
      "1. The avoidance message accurately names the pattern but feels accusatory. \n",
      "2. The motivation message is encouraging but too vague about specific action. \n",
      "3. The committed-action message is closest but doesn't address the core distrust issue.\n",
      "\n",
      "Best path forward: Reframe resistance as data. We need to validate the struggle while gently challenging the avoidance. The rewritten message should:\n",
      "- Acknowledge the homework friction (\"I know those exercises felt irrelevant...\")\n",
      "- Normalize resistance (\"That pull to avoid is understandable...\")\n",
      "- Link willingness to values (\"...when you choose to lean in anyway\")\n",
      "- End with actionable reframing (\"...you're gathering crucial information\")\n",
      "\n",
      "The chosen message transforms resistance from a failure into part of the process - exactly what ACT teaches about creative hopelessness. By focusing on \"what you learn about avoidance patterns,\" it makes the resistance itself therapeutic material rather than a barrier.\n",
      "</think>\n",
      "\n",
      "\n",
      "Based on the client's avoidance patterns, resistance to self-assessment, and the therapeutic focus on workability and willingness, the best message is:\n",
      "\n",
      "**Rewritten Message:**  \n",
      "*\"I know those exercises felt irrelevant or frustrating when difficult feelings arose. That pull to avoid is understandable. Yet when you choose to lean in anyway—even just noticing what happens when you try—you're gathering crucial information about what actually works for your life. What do you learn?\"*\n",
      "\n",
      "### Why this message works:\n",
      "1.  **Validates Experience:** Acknowledges the client's frustration (\"felt irrelevant or frustrating,\" \"pull to avoid is understandable\") which builds rapport and reduces defensiveness.\n",
      "2.  **Names Avoidance:** Gently labels the avoidance dynamic (\"pull to avoid\") without judgment, aligning with the therapist's session focus.\n",
      "3.  **Emphasizes Willingness & Curiosity:** Shifts focus to *choosing to engage* (\"when you choose to lean in anyway\") and frames effort as data-gathering (\"gathering crucial information\"), appealing to the client's stated value of understanding.\n",
      "4.  **Prioritizes Workability:** Directly ties to the core ACT principle discussed (\"information about what actually works for your life\").\n",
      "5.  **Actionable & Open-Ended:** Ends with an invitation to self-observe (\"What do you learn?\"), encouraging reflection on internal experience rather than demanding behavioral compliance.\n",
      "6.  **Short & Clinically Grounded:** Uses\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Setting up Hugging Face API and DeepSeek model\n",
    "HF_TOKEN = \"Your API Key\"\n",
    "MODEL_ID = \"deepseek-ai/DeepSeek-R1-0528:novita\"\n",
    "\n",
    "# Initializing Hugging Face client with OpenAI compatibility\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=HF_TOKEN,\n",
    ")\n",
    "\n",
    "# Loading all notification messages from file\n",
    "def load_notifications(filepath=\"notifications.txt\"):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return [chunk.strip() for chunk in text.strip().split(\"\\n\\n\") if chunk.strip()]\n",
    "\n",
    "notification_chunks = load_notifications(\"notifications.txt\")\n",
    "print(f\"Loaded {len(notification_chunks)} notification messages.\")\n",
    "\n",
    "# Creating embeddings and FAISS index for the notifications\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "notification_embeddings = embedding_model.encode(notification_chunks, convert_to_numpy=True)\n",
    "\n",
    "dimension = notification_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(notification_embeddings.astype(\"float32\"))\n",
    "\n",
    "# Saving the index and notification metadata for later use\n",
    "with open(\"notification_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(notification_chunks, f, indent=2)\n",
    "faiss.write_index(index, \"notification_index.faiss\")\n",
    "\n",
    "print(\"Saved notification index.\")\n",
    "\n",
    "# Loading the session summary and transcript\n",
    "with open(\"Deepseek S3 Bottom Up Summary.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_summary = f.read().strip()\n",
    "\n",
    "with open(\"Session Three.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_transcript = f.read().strip()\n",
    "\n",
    "# Limiting transcript length to about 700 words for processing\n",
    "session_transcript = ' '.join(session_transcript.split()[:700])\n",
    "\n",
    "# Retrieving top-k relevant notification messages using FAISS\n",
    "query_embedding = embedding_model.encode([session_summary], convert_to_numpy=True)\n",
    "D, I = index.search(np.array(query_embedding).astype(\"float32\"), k=3)\n",
    "top_messages = [notification_chunks[i] for i in I[0]]\n",
    "\n",
    "# Creating system and user prompts with session and candidate messages\n",
    "system_prompt = \"You are a psychologist selecting a helpful message to send to a client between sessions. Use ACT principles.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Session Summary:\n",
    "---\n",
    "{session_summary}\n",
    "\n",
    "Transcript (partial):\n",
    "---\n",
    "{session_transcript}\n",
    "\n",
    "Candidate Messages:\n",
    "---\n",
    "{chr(10).join(top_messages)}\n",
    "\n",
    "Task:\n",
    "Choose the best message for this client or rewrite a better one. It should be short, actionable, and grounded in ACT.\n",
    "\"\"\"\n",
    "\n",
    "# Sending the request to the DeepSeek model for message suggestion\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "# Displaying the suggested between-session message\n",
    "suggested_message = response.choices[0].message.content.strip()\n",
    "print(\"\\nSuggested Between-Session Message:\\n\")\n",
    "print(suggested_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5acd7eb2-d636-42e5-892d-6eb4296b0d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 notification messages.\n",
      "Saved notification index.\n",
      "\n",
      " Suggested Between-Session Message:\n",
      "\n",
      "Based on the session summary, I would recommend the following message:\n",
      "\n",
      "**Pain is a normal part of life. Rather than avoiding or fighting it, we can make space for it and choose how to respond.**\n",
      "\n",
      "This message is grounded in ACT principles, specifically acceptance. It acknowledges the client's pain and resistance, while encouraging them to approach their emotions in a more direct and honest way. By framing pain as a normal part of life, the message helps to reduce shame and increase willingness to confront difficult emotions.\n",
      "\n",
      "This message is also short, actionable, and easy to understand, making it a good fit for a client who may be struggling with intellectualization and avoidance. It invites the client to take a more mindful and values-driven approach to their emotions, rather than getting caught up in fusion or avoidance.\n",
      "\n",
      "Here's a possible follow-up message that builds on this one:\n",
      "\n",
      "**What might you gain by making space for your emotions, rather than avoiding or fighting them?**\n",
      "\n",
      "This message encourages the client to reflect on the potential benefits of acceptance, and to consider how it might align with their values and goals. It also invites the client to take a more active and intentional approach to their emotions, rather than simply avoiding or resisting them.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Setting up Hugging Face API and Meta Llama model\n",
    "HF_TOKEN = \"Your API Key\"\n",
    "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct:cerebras\"\n",
    "\n",
    "# Initializing Hugging Face client with OpenAI-compatible API\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=HF_TOKEN,\n",
    ")\n",
    "\n",
    "# Loading all notification messages from file\n",
    "def load_notifications(filepath=\"notifications.txt\"):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return [chunk.strip() for chunk in text.strip().split(\"\\n\\n\") if chunk.strip()]\n",
    "\n",
    "notification_chunks = load_notifications(\"notifications.txt\")\n",
    "print(f\"Loaded {len(notification_chunks)} notification messages.\")\n",
    "\n",
    "# Creating embeddings and FAISS index for the notification messages\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "notification_embeddings = embedding_model.encode(notification_chunks, convert_to_numpy=True)\n",
    "\n",
    "dimension = notification_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(notification_embeddings.astype(\"float32\"))\n",
    "\n",
    "# Saving index and notification chunks for later use\n",
    "with open(\"notification_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(notification_chunks, f, indent=2)\n",
    "faiss.write_index(index, \"notification_index.faiss\")\n",
    "\n",
    "print(\"Saved notification index.\")\n",
    "\n",
    "# Loading session summary and transcript files\n",
    "with open(\"Meta S3 Bottom Up Summary.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_summary = f.read().strip()\n",
    "\n",
    "with open(\"Session Three.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_transcript = f.read().strip()\n",
    "\n",
    "# Limiting transcript length to about 700 words for processing\n",
    "session_transcript = ' '.join(session_transcript.split()[:700])\n",
    "\n",
    "# Retrieving top-k relevant notification messages using FAISS search\n",
    "query_embedding = embedding_model.encode([session_summary], convert_to_numpy=True)\n",
    "D, I = index.search(np.array(query_embedding).astype(\"float32\"), k=3)\n",
    "top_messages = [notification_chunks[i] for i in I[0]]\n",
    "\n",
    "# Constructing system and user prompts for the model\n",
    "system_prompt = \"You are a psychologist selecting a helpful message to send to a client between sessions. Use ACT principles.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Session Summary:\n",
    "---\n",
    "{session_summary}\n",
    "\n",
    "Transcript (partial):\n",
    "---\n",
    "{session_transcript}\n",
    "\n",
    "Candidate Messages:\n",
    "---\n",
    "{chr(10).join(top_messages)}\n",
    "\n",
    "Task:\n",
    "Choose the best message for this client or rewrite a better one. It should be short, actionable, and grounded in ACT.\n",
    "\"\"\"\n",
    "\n",
    "# Sending the request to the Meta Llama model for message suggestion\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "# Printing the suggested between-session message\n",
    "suggested_message = response.choices[0].message.content.strip()\n",
    "print(\"\\nSuggested Between-Session Message:\\n\")\n",
    "print(suggested_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2c301f-d9ec-4f0a-9b88-b9b58d5ffd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 notification messages.\n",
      "Saved notification index.\n",
      "\n",
      " Suggested Between-Session Message:\n",
      "\n",
      "“Between now and next time, notice one moment you’re tempted to shove the feeling down or out-run it. Instead of fixing it, pause, name it (‘here’s anger,’ ‘here’s shame’), and ask: ‘If I stop arguing with this for 5 seconds, what tiny move toward the person I want to be becomes possible?’ Do it or don’t—just watch what happens and bring the story to our next session.”\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Setting up Hugging Face API and Moonshot model\n",
    "HF_TOKEN = \"Your API Key\"\n",
    "MODEL_ID = \"moonshotai/Kimi-K2-Instruct:novita\"\n",
    "\n",
    "# Initializing Hugging Face client with OpenAI-compatible API\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=HF_TOKEN,\n",
    ")\n",
    "\n",
    "# Loading all notification messages from file\n",
    "def load_notifications(filepath=\"notifications.txt\"):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return [chunk.strip() for chunk in text.strip().split(\"\\n\\n\") if chunk.strip()]\n",
    "\n",
    "notification_chunks = load_notifications(\"notifications.txt\")\n",
    "print(f\"Loaded {len(notification_chunks)} notification messages.\")\n",
    "\n",
    "# Creating embeddings and FAISS index for the notification messages\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "notification_embeddings = embedding_model.encode(notification_chunks, convert_to_numpy=True)\n",
    "\n",
    "dimension = notification_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(notification_embeddings.astype(\"float32\"))\n",
    "\n",
    "# Saving index and notification chunks for later use\n",
    "with open(\"notification_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(notification_chunks, f, indent=2)\n",
    "faiss.write_index(index, \"notification_index.faiss\")\n",
    "\n",
    "print(\"Saved notification index.\")\n",
    "\n",
    "# Loading session summary and transcript files\n",
    "with open(\"Moonshot S3 Bottom Up Summary.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_summary = f.read().strip()\n",
    "\n",
    "with open(\"Session Three.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    session_transcript = f.read().strip()\n",
    "\n",
    "# Limiting transcript length to about 700 words for processing\n",
    "session_transcript = ' '.join(session_transcript.split()[:700])\n",
    "\n",
    "# Retrieving top-k relevant notification messages using FAISS search\n",
    "query_embedding = embedding_model.encode([session_summary], convert_to_numpy=True)\n",
    "D, I = index.search(np.array(query_embedding).astype(\"float32\"), k=3)\n",
    "top_messages = [notification_chunks[i] for i in I[0]]\n",
    "\n",
    "# Constructing system and user prompts for the model\n",
    "system_prompt = \"You are a psychologist selecting a helpful message to send to a client between sessions. Use ACT principles.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Session Summary:\n",
    "---\n",
    "{session_summary}\n",
    "\n",
    "Transcript (partial):\n",
    "---\n",
    "{session_transcript}\n",
    "\n",
    "Candidate Messages:\n",
    "---\n",
    "{chr(10).join(top_messages)}\n",
    "\n",
    "Task:\n",
    "Choose the best message for this client or rewrite a better one. It should be short, actionable, and grounded in ACT.\n",
    "\"\"\"\n",
    "\n",
    "# Sending the request to the Moonshot model for message suggestion\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL_ID,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0.4,\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "# Printing the suggested between-session message\n",
    "suggested_message = response.choices[0].message.content.strip()\n",
    "print(\"\\nSuggested Between-Session Message:\\n\")\n",
    "print(suggested_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538e376-56b7-46d9-b670-445acf58f37b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
